{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Bagging Classifier with Decision Trees\n",
    "bagging = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bagging.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create a Bagging Classifier with Decision Trees\n",
    "bagging = BaggingClassifier(bootstrap= False, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bagging.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6693561 , -1.49577819, -0.87076638, ..., -1.26733697,\n",
       "        -1.2763343 ,  1.01664321],\n",
       "       [ 0.09337237,  0.78584826,  0.10575379, ..., -0.12270893,\n",
       "         0.6934308 ,  0.91136272],\n",
       "       [-0.90579721, -0.60834121,  0.29514098, ...,  0.83049813,\n",
       "        -0.73733198, -0.5782121 ],\n",
       "       ...,\n",
       "       [-0.20013455, -1.46108168,  1.79701652, ..., -1.50280171,\n",
       "        -1.27473745,  1.60111869],\n",
       "       [ 0.03935575,  0.24868361, -0.47532342, ...,  0.09912579,\n",
       "         0.54269228,  1.20827474],\n",
       "       [ 0.76921528,  0.47076539,  0.16994471, ...,  0.6561162 ,\n",
       "         0.64333186, -2.02100232]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Bagging Classifier with Decision Trees\n",
    "bagging = BaggingClassifier(estimator=SVC())\n",
    "\n",
    "# Train the model\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bagging.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Bagging Classifier with Decision Trees\n",
    "bag= BaggingClassifier(n_estimators=500, bootstrap=False,max_features=0.5, bootstrap_features=True, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bag.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.estimators_features_[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Bagging Classifier with Decision Trees\n",
    "bag= BaggingClassifier(n_estimators=500, bootstrap=False,max_samples=0.6, max_features=0.5, bootstrap_features=True, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bag.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 12,  2,  9,  7,  7, 19, 18,  9])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.estimators_samples_[0]\n",
    "bag.estimators_features_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OOB score (Out-Of-Bag score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Bagging Classifier with Decision Trees\n",
    "bag= BaggingClassifier(n_estimators=500,max_samples=0.6, max_features=0.5, bootstrap=True, random_state=42, oob_score=True)\n",
    "\n",
    "# Train the model\n",
    "bag.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bag.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(\"Bagging Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90125"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.6494377401616743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Generate synthetic regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.2, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Bagging Regressor using Decision Tree as base estimator\n",
    "bag_reg = BaggingRegressor(\n",
    "    n_estimators=100,         # Number of trees in the ensemble\n",
    "    max_samples=0.8,          # Use 80% of data for each model\n",
    "    max_features=0.5,         # Use 50% of features for each model\n",
    "    random_state=42,\n",
    "    n_jobs=-1                 # Use all processors\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "bag_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bag_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance using Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.878836748979433\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv')\n",
    "X = df.iloc[:,0:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Bagging Regressor using Decision Tree as base estimator\n",
    "bag_reg = BaggingRegressor(\n",
    "    n_estimators=150,         # Number of trees in the ensemble\n",
    "    max_samples=0.8,          # Use 80% of data for each model\n",
    "    n_jobs=-1                 # Use all processors\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "bag_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = bag_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance using Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Regressor vs Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score for LR 0.6687594935356317\n",
      "R^2 score for DT 0.6772947602240251\n",
      "R^2 score for KNN 0.6473640882039258\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor()\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "dt.fit(X_train,y_train)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "y_pred1 = lr.predict(X_test)\n",
    "y_pred2 = dt.predict(X_test)\n",
    "y_pred3 = knn.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"R^2 score for LR\",r2_score(y_test,y_pred1))\n",
    "print(\"R^2 score for DT\",r2_score(y_test,y_pred2))\n",
    "print(\"R^2 score for KNN\",r2_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968543750126283"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_samples': 0.7, 'n_estimators': 100}\n",
      "Best score: 0.8289737646551041\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': [20,50,100,150],\n",
    "          'max_samples': [0.5,0.7,0.8,0.9,1.0],\n",
    "          \n",
    "       \n",
    "           \n",
    "          }\n",
    "\n",
    "bagging_regressor_grid = GridSearchCV(BaggingRegressor(n_jobs=-1), param_grid =params, cv=5,scoring='r2', n_jobs=-1)\n",
    "bagging_regressor_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {bagging_regressor_grid.best_params_}\")\n",
    "print(f\"Best score: {bagging_regressor_grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R² with GridSearch Best Model: 0.8657965834984654\n"
     ]
    }
   ],
   "source": [
    "best_bag_reg = bagging_regressor_grid.best_estimator_\n",
    "best_bag_reg\n",
    "\n",
    "y_pred_best = best_bag_reg.predict(X_test)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "print(f\"Test R² with GridSearch Best Model: {r2_best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 100, 'max_samples': 0.5, 'max_features': 0.8, 'bootstrap_features': False, 'bootstrap': False}\n",
      "Best score: 0.8315491149018766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {'n_estimators': [20,50,100,150],\n",
    "          'max_samples': [0.5,0.7,0.8,0.9,1.0],\n",
    "          'max_features': [0.5, 0.6, 0.7,0.8],\n",
    "          'bootstrap': [True, False],\n",
    "          'bootstrap_features': [True, False]  \n",
    "          }\n",
    "\n",
    "rrcv = RandomizedSearchCV(BaggingRegressor(n_jobs=-1), params, cv=5,scoring='r2', n_jobs=-1)\n",
    "rrcv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {rrcv.best_params_}\")\n",
    "print(f\"Best score: {rrcv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R² with GridSearch Best Model: 0.8583410311025145\n"
     ]
    }
   ],
   "source": [
    "best_rscv = rrcv.best_estimator_\n",
    "\n",
    "\n",
    "y_pred_best = best_rscv.predict(X_test)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "print(f\"Test R² with GridSearch Best Model: {r2_best}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

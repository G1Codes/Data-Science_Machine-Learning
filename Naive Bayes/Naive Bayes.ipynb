{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Gaussian Naive Bayes model\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [1, 2, 4], [4, 5, 3]])\n",
    "y = np.array([0, 1, 0, 1])  \n",
    "\n",
    "cat_nb = CategoricalNB()\n",
    "cat_nb.fit(X, y)\n",
    "\n",
    "print(cat_nb.predict([[1, 2, 3]]))  # Output: class label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (Multinomial): [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Example text data\n",
    "texts = [\"I love programming\", \"I hate bugs\", \"Programming is fun\", \"Bugs are annoying\"]\n",
    "labels = [1, 0, 1, 0]  # 1 = positive, 0 = negative\n",
    "\n",
    "# Convert text to feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Train Multinomial Naive Bayes\n",
    "model = MultinomialNB()  # alpha=1 (default) --> Laplace Smoothing\n",
    "model.fit(X, labels)\n",
    "\n",
    "# Predict\n",
    "new_text = [\"I love coding\"]\n",
    "new_X = vectorizer.transform(new_text)\n",
    "print(\"Prediction (Multinomial):\", model.predict(new_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "emails = [\"Free money now\", \"Click to win a prize\", \"Hello, how are you?\", \"Let's meet for coffee\"]\n",
    "labels = [1, 1, 0, 0]  # 1 = spam, 0 = not spam\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(emails)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X, labels)\n",
    "\n",
    "print(mnb.predict(vectorizer.transform([\"Win free cash\"])))  # Output: [1] (spam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes (BNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (Bernoulli): [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Example binary data\n",
    "X = [[1, 0, 1], [0, 1, 0], [1, 1, 0], [0, 0, 1]]\n",
    "y = [1, 0, 1, 0]  # 1 = positive, 0 = negative\n",
    "\n",
    "# Train Bernoulli Naive Bayes\n",
    "model = BernoulliNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "new_X = [[1, 0, 0]]\n",
    "print(\"Prediction (Bernoulli):\", model.predict(new_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset with specified encoding\n",
    "df = pd.read_csv(r\"https://raw.githubusercontent.com/shrudex/sms-spam-detection/refs/heads/main/sms-spam.csv\")\n",
    "\n",
    "\n",
    "#Convert labels to binary (spam = 1, ham = 0)\n",
    "df['v1'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "df.dropna(axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vocabulary size:', 8405)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert text to binary features\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['v2'])\n",
    "\n",
    "# Labels (spam = 1, ham = 0)\n",
    "y = df['v1']\n",
    "\n",
    "# Split into training & testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\"Vocabulary size:\", len(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9748878923766816\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       0.98      0.83      0.90       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.91      0.94      1115\n",
      "weighted avg       0.98      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Bernoulli Na√Øve Bayes\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = bnb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complement Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (Complement): [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "# Example imbalanced data\n",
    "X = [[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]]\n",
    "y = [0, 0, 0, 0, 1, 1]  # Imbalanced classes\n",
    "\n",
    "# Train Complement Naive Bayes\n",
    "model = ComplementNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "new_X = [[2, 3]]\n",
    "print(\"Prediction (Complement):\", model.predict(new_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam Classifier using Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset with specified encoding\n",
    "df = pd.read_csv(r\"https://raw.githubusercontent.com/shrudex/sms-spam-detection/refs/heads/main/sms-spam.csv\")\n",
    "\n",
    "\n",
    "#Convert labels to binary (spam = 1, ham = 0)\n",
    "df['v1'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "df.dropna(axis=1, inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vocabulary size:', 8405)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "X = df['v2']\n",
    "y=df['v1']\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['v2'])\n",
    "\n",
    "model = ComplementNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\"Vocabulary size:\", len(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9408071748878923\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       965\n",
      "           1       0.71      0.96      0.81       150\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.85      0.95      0.89      1115\n",
      "weighted avg       0.95      0.94      0.94      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Bernoulli Na√Øve Bayes\n",
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = cnb.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: 'Win money now!!!' ‚Üí Spam\n",
      "Message: 'Hello, how are you?' ‚Üí Ham\n",
      "Message: 'Click this link to claim your prize!' ‚Üí Spam\n"
     ]
    }
   ],
   "source": [
    "# Test with new messages\n",
    "new_messages = [\"Win money now!!!\", \"Hello, how are you?\", \"Click this link to claim your prize!\"]\n",
    "X_new = vectorizer.transform(new_messages)\n",
    "\n",
    "# Predict spam or ham\n",
    "predictions = cnb.predict(X_new)\n",
    "\n",
    "for msg, pred in zip(new_messages, predictions):\n",
    "    print(f\"Message: '{msg}' ‚Üí {'Spam' if pred == 1 else 'Ham'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: 'You won a lottery! Claim your prize now!' ‚Üí Spam\n",
      "Message: 'Hello, how are you?' ‚Üí Ham\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load a large dataset (Example: Spam detection)\n",
    "df = pd.read_csv(r\"https://raw.githubusercontent.com/shrudex/sms-spam-detection/refs/heads/main/sms-spam.csv\")\n",
    "df.dropna(inplace=True, axis=1)\n",
    "df.columns = [\"label\", \"message\"]\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})  # Convert labels to binary\n",
    "\n",
    "# Convert text into numerical features\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['message'])  # Convert text to bag-of-words\n",
    "y = df['label'].values\n",
    "\n",
    "# Split data into smaller chunks (simulate streaming)\n",
    "chunk_size = 1000  # Process 1000 rows at a time\n",
    "num_chunks = X.shape[0] // chunk_size\n",
    "\n",
    "# Initialize Na√Øve Bayes model for out-of-core learning\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Train model in chunks using partial_fit\n",
    "for i in range(num_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = start + chunk_size\n",
    "    X_chunk, y_chunk = X[start:end], y[start:end]\n",
    "    \n",
    "    if i == 0:\n",
    "        nb.partial_fit(X_chunk, y_chunk, classes=np.array([0, 1]))  # Initialize with all classes\n",
    "    else:\n",
    "        nb.partial_fit(X_chunk, y_chunk)  # Incrementally update model\n",
    "\n",
    "# Predict on new data\n",
    "new_messages = [\"You won a lottery! Claim your prize now!\", \"Hello, how are you?\"]\n",
    "X_new = vectorizer.transform(new_messages)\n",
    "predictions = nb.predict(X_new)\n",
    "\n",
    "# Output results\n",
    "for msg, pred in zip(new_messages, predictions):\n",
    "    print(f\"Message: '{msg}' ‚Üí {'Spam' if pred == 1 else 'Ham'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
